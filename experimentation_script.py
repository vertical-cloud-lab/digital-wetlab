# Generated by Honegumi (https://arxiv.org/abs/2502.06815)
# %pip install ax-platform==0.4.3
import numpy as np
from ax.service.ax_client import AxClient, ObjectiveProperties, GenerationStrategy
from ax.modelbridge.generation_node import GenerationNode
from ax.modelbridge.generation_strategy import GenerationStep, GenerationStrategy
from ax.modelbridge.modelbridge_utils import get_pending_observation_features
from ax.modelbridge.registry import ModelRegistryBase, Models


# define these names as variables for reuse (e.g., branin function return)
obj1_name = "precipitate"

gs = GenerationStrategy(
    steps=[
        GenerationStep(
            model=Models.SOBOL,
            num_trials=1000,
            max_parallelism=10
        ), 
        GenerationStep(
            model=Models.BOTORCH_MODULAR,
            num_trials=9000,  # No limitation on how many trials should be produced from this step
            max_parallelism=3,  # Parallelism limit for this step, often lower than for Sobol
        ),
    ]
)

ax_client = AxClient(generation_strategy=gs)

# Define your search space and objectives
ax_client.create_experiment(
    parameters=[
        {"name": "x1", "type": "range", "bounds": [-5.0, 10.0]},
        {"name": "x2", "type": "range", "bounds": [0.0, 10.0]},
    ],
    objectives={
        obj1_name: ObjectiveProperties(minimize=False),
    },
)


# optimization loop
for _ in range(10000):

    # get_next_trial performs model fitting and acquisition function evaluation
    parameterization, trial_index = ax_client.get_next_trial()

    # extract parameters
    x1 = parameterization["x1"]
    x2 = parameterization["x2"]

    # evaluate the dummy objective function
    # results = branin(x1, x2)
    # report the results back to the algorithm
    # ax_client.complete_trial(trial_index=trial_index, raw_data=results)

# best in-sample parameterization as predicted by model
best_parameters, metrics = ax_client.get_best_parameters()

                